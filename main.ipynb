{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "__A0XXcthVKp",
    "outputId": "c98207bf-dd69-470c-c1a2-4bcc75dd6791"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.42.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.6)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (17.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (13.9.4)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.5)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.25.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit\n",
    "!pip install pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6aL98HsoXBkt",
    "outputId": "c5759bdb-6a4b-44f7-fb41-818bec27459a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "# Load your dataset\n",
    "online_sales = pd.read_csv(\"Online_Sales.csv\")\n",
    "custmer = pd.read_excel(\"CustomersData.xlsx\")\n",
    "\n",
    "# Merge datasets (adjust as necessary)\n",
    "data = pd.merge(online_sales, custmer, on=\"CustomerID\", how=\"left\")\n",
    "data.Transaction_Date = pd.to_datetime(data.Transaction_Date, format = \"%Y%m%d\")\n",
    "data.sort_values(by=['CustomerID', 'Transaction_Date'], inplace=True)\n",
    "# Example logic to create 'Next_Purchase' column\n",
    "# Assuming 'Purchase_Date' is a column in your online_sales dataset\n",
    "data['Purchase_Date'] = pd.to_datetime(data['Transaction_Date'])  # Ensure it's in datetime format\n",
    "data.sort_values(by=['CustomerID', 'Purchase_Date'], inplace=True)\n",
    "\n",
    "# Create a 'Next_Purchase' column\n",
    "data['Next_Purchase'] = data.groupby('CustomerID')['Purchase_Date'].shift(-1).notnull().astype(int)\n",
    "\n",
    "# Prepare your features and target variable\n",
    "X = data[['Quantity', 'Avg_Price', 'Delivery_Charges']]  # Add other relevant features\n",
    "y = data['Next_Purchase']  # This is your target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "1fsFCfR6vlPt"
   },
   "outputs": [],
   "source": [
    "# Create a Streamlit app\n",
    "with open('app.py', 'w') as f:\n",
    "    f.write(\n",
    "        \"\"\"\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Load your pre-trained models\n",
    "try:\n",
    "    with open('model.pkl', 'rb') as model_file:\n",
    "        purchase_model = pickle.load(model_file)\n",
    "    with open('product_model.pkl', 'rb') as product_model_file:  # Load the new product prediction model\n",
    "        product_model = pickle.load(product_model_file)\n",
    "    st.write(\"Models loaded successfully!\")\n",
    "except Exception as e:\n",
    "    purchase_model = None\n",
    "    product_model = None\n",
    "    st.error(f\"Error loading models: {e}\")\n",
    "\n",
    "# Ensure models are loaded before using them\n",
    "if purchase_model is None or product_model is None:\n",
    "    st.stop()  # Stop the app if the models are not loaded\n",
    "\n",
    "# Load data\n",
    "dis = pd.read_csv(\"Discount_Coupon.csv\")\n",
    "markt = pd.read_csv(\"Marketing_Spend.csv\")\n",
    "online_sales = pd.read_csv(\"Online_Sales.csv\")\n",
    "custmer = pd.read_excel(\"CustomersData.xlsx\")\n",
    "tax = pd.read_excel(\"Tax_amount.xlsx\")\n",
    "\n",
    "# Merge datasets\n",
    "online_sales_custmer = pd.merge(online_sales, custmer, on=\"CustomerID\", how=\"left\")\n",
    "o_c_t = pd.merge(online_sales_custmer, tax, on=\"Product_Category\", how=\"left\")\n",
    "o_c_t.Transaction_Date = pd.to_datetime(o_c_t.Transaction_Date, format=\"%Y%m%d\")\n",
    "\n",
    "# Calculate the date difference\n",
    "o_c_t = o_c_t.sort_values(by=['CustomerID', 'Transaction_Date'])  # Sort by CustomerID and Transaction_Date\n",
    "o_c_t['Days_Since_Last_Transaction'] = o_c_t.groupby('CustomerID')['Transaction_Date'].diff().dt.days\n",
    "\n",
    "# Title\n",
    "st.title(\"Customer Segmentation and Next Purchase Prediction\")\n",
    "\n",
    "# Sidebar for user input\n",
    "st.sidebar.header(\"User Input Features\")\n",
    "\n",
    "# User input for customer features\n",
    "customer_id_input = st.sidebar.text_input(\"Enter Customer ID (or select from the dropdown)\")\n",
    "\n",
    "if customer_id_input:\n",
    "    try:\n",
    "        customer_id = int(customer_id_input)\n",
    "    except ValueError:\n",
    "        st.error(\"Cannot make predictions as no data is available for the entered Customer ID\")\n",
    "        st.stop()\n",
    "else:\n",
    "    customer_id = st.sidebar.selectbox(\"Select Customer ID\", o_c_t['CustomerID'].unique())\n",
    "\n",
    "customer_data = o_c_t[o_c_t['CustomerID'] == customer_id]\n",
    "\n",
    "# Display customer data\n",
    "if not customer_data.empty:\n",
    "    st.write(\"Customer Data:\")\n",
    "    st.write(customer_data)\n",
    "else:\n",
    "    st.warning(\"No data found for the entered Customer ID.\")\n",
    "\n",
    "# Features for prediction\n",
    "# Assuming these are the features used to train the product_model\n",
    "expected_product_features = ['Quantity', 'Avg_Price', 'Delivery_Charges']  # Adjust this list based on your model\n",
    "\n",
    "# Filter X_input to only include the expected features\n",
    "X_input = customer_data[expected_product_features]\n",
    "\n",
    "# Button to perform purchase prediction\n",
    "if st.sidebar.button(\"Predict Next Purchase\"):\n",
    "    if purchase_model is not None:\n",
    "        if not customer_data.empty:\n",
    "            # Predict the next purchase using the pre-trained model\n",
    "            next_purchase_prediction = purchase_model.predict(X_input)\n",
    "\n",
    "            # Check the sum of 'Days_Since_Last_Transaction'\n",
    "            total_days_since_last_transaction = customer_data['Days_Since_Last_Transaction'].sum()\n",
    "\n",
    "            # Logic to determine likelihood based on days since last transaction\n",
    "            if total_days_since_last_transaction > 1:\n",
    "                st.write(\"Prediction: The customer is likely to make a next purchase (based on transaction history).\")\n",
    "            else:\n",
    "                # Display the prediction from the model\n",
    "                if next_purchase_prediction[0] == 1:\n",
    "                    st.write(\"Prediction: The customer is likely to make a next purchase (based on model prediction).\")\n",
    "                else:\n",
    "                    st.write(\"Prediction: The customer is unlikely to make a next purchase.\")\n",
    "        else:\n",
    "            st.warning(\"Cannot make predictions as no data is available for the entered Customer ID.\")\n",
    "    else:\n",
    "        st.error(\"Purchase model is not loaded, unable to make predictions.\")\n",
    "\n",
    "# Button to predict next product\n",
    "if st.sidebar.button(\"Predict Next Product\"):\n",
    "    if product_model is not None:\n",
    "        if not customer_data.empty:\n",
    "            # Predict the next product using the pre-trained product model\n",
    "            next_product_prediction = product_model.predict(X_input)\n",
    "\n",
    "            # Display the prediction\n",
    "            st.write(f\"Prediction: The customer is likely to buy {next_product_prediction[0]}.\")\n",
    "        else:\n",
    "            st.warning(\"Cannot make predictions as no data is available for the entered Customer ID.\")\n",
    "    else:\n",
    "        st.error(\"Product model is not loaded, unable to make predictions.\")\n",
    "\n",
    "\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5VorBd25bb7O",
    "outputId": "e764ac98-84ff-4e88-b8f9-d280c2fe9e44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pickle\n",
    "\n",
    "# Assuming 'data' is your dataframe\n",
    "# Create the 'Next_Product' column, which shifts the 'Product_Category' to get the next purchase\n",
    "data['Next_Product'] = data.groupby('CustomerID')['Product_Category'].shift(-1)\n",
    "\n",
    "# Handle missing values by removing rows with NaN in any of the important columns\n",
    "data = data.dropna(subset=['Quantity', 'Avg_Price', 'Delivery_Charges', 'Next_Product'])\n",
    "\n",
    "# Prepare features and target variable\n",
    "X_product = data[['Quantity', 'Avg_Price', 'Delivery_Charges']]  # Add other relevant features\n",
    "y_product = data['Next_Product']  # This is your target variable\n",
    "\n",
    "# Train the RandomForest model\n",
    "product_model = RandomForestClassifier()\n",
    "product_model.fit(X_product, y_product)\n",
    "\n",
    "# Save the trained model to a file\n",
    "with open('product_model.pkl', 'wb') as product_model_file:\n",
    "    pickle.dump(product_model, product_model_file)\n",
    "\n",
    "print(\"Model trained and saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_e1JAH6GYEo7",
    "outputId": "01c24a42-6ca5-417b-edca-9dc800aa1e32"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-09 07:55:30.875 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-09 07:55:30.878 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-09 07:55:30.881 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-09 07:55:30.884 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-09 07:55:31.844 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-09 07:55:31.855 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-09 07:55:31.861 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-09 07:55:31.867 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-09 07:55:31.870 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-09 07:55:31.876 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-09 07:55:31.881 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-09 07:55:31.887 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-09 07:55:31.890 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-09 07:55:31.897 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-09 07:55:31.903 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-09 07:55:31.914 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-09 07:55:31.916 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-09 07:55:31.922 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-09 07:55:31.929 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-09 07:55:31.934 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-09 07:55:31.944 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-09 07:55:31.949 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-09 07:55:31.952 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-09 07:55:31.955 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-09 07:55:31.958 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-09 07:55:31.962 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-09 07:55:31.966 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-09 07:55:31.976 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-09 07:55:31.980 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-09 07:55:31.983 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Load your pre-trained models\n",
    "try:\n",
    "    with open('model.pkl', 'rb') as model_file:\n",
    "        purchase_model = pickle.load(model_file)\n",
    "    with open('product_model.pkl', 'rb') as product_model_file:  # Load the new product prediction model\n",
    "        product_model = pickle.load(product_model_file)\n",
    "    st.write(\"Models loaded successfully!\")\n",
    "except Exception as e:\n",
    "    purchase_model = None\n",
    "    product_model = None\n",
    "    st.error(f\"Error loading models: {e}\")\n",
    "\n",
    "# Ensure models are loaded before using them\n",
    "if purchase_model is None or product_model is None:\n",
    "    st.stop()  # Stop the app if the models are not loaded\n",
    "\n",
    "# Load data\n",
    "dis = pd.read_csv(\"Discount_Coupon.csv\")\n",
    "markt = pd.read_csv(\"Marketing_Spend.csv\")\n",
    "online_sales = pd.read_csv(\"Online_Sales.csv\")\n",
    "custmer = pd.read_excel(\"CustomersData.xlsx\")\n",
    "tax = pd.read_excel(\"Tax_amount.xlsx\")\n",
    "\n",
    "# Merge datasets\n",
    "online_sales_custmer = pd.merge(online_sales, custmer, on=\"CustomerID\", how=\"left\")\n",
    "o_c_t = pd.merge(online_sales_custmer, tax, on=\"Product_Category\", how=\"left\")\n",
    "o_c_t.Transaction_Date = pd.to_datetime(o_c_t.Transaction_Date, format=\"%Y%m%d\")\n",
    "\n",
    "# Calculate the date difference\n",
    "o_c_t = o_c_t.sort_values(by=['CustomerID', 'Transaction_Date'])  # Sort by CustomerID and Transaction_Date\n",
    "o_c_t['Days_Since_Last_Transaction'] = o_c_t.groupby('CustomerID')['Transaction_Date'].diff().dt.days\n",
    "\n",
    "# Title\n",
    "st.title(\"Customer Segmentation and Next Purchase Prediction\")\n",
    "\n",
    "# Sidebar for user input\n",
    "st.sidebar.header(\"User Input Features\")\n",
    "\n",
    "# User input for customer features\n",
    "customer_id = st.sidebar.selectbox(\"Select Customer ID\", o_c_t['CustomerID'].unique())\n",
    "customer_data = o_c_t[o_c_t['CustomerID'] == customer_id]\n",
    "\n",
    "# Display customer data\n",
    "st.write(\"Customer Data:\")\n",
    "st.write(customer_data)\n",
    "\n",
    "# Features for prediction\n",
    "# Assuming these are the features used to train the product_model\n",
    "expected_product_features = ['Quantity', 'Avg_Price', 'Delivery_Charges']  # Adjust this list based on your model\n",
    "\n",
    "# Filter X_input to only include the expected features\n",
    "X_input = customer_data[expected_product_features]\n",
    "\n",
    "# Button to perform purchase prediction\n",
    "if st.sidebar.button(\"Predict Next Purchase\"):\n",
    "    if purchase_model is not None:\n",
    "        # Predict the next purchase using the pre-trained model\n",
    "        next_purchase_prediction = purchase_model.predict(X_input)\n",
    "\n",
    "        # Check the sum of 'Days_Since_Last_Transaction'\n",
    "        total_days_since_last_transaction = customer_data['Days_Since_Last_Transaction'].sum()\n",
    "\n",
    "        # Logic to determine likelihood based on days since last transaction\n",
    "        if total_days_since_last_transaction > 1:\n",
    "            st.write(\"Prediction: The customer is likely to make a next purchase (based on transaction history).\")\n",
    "        else:\n",
    "            # Display the prediction from the model\n",
    "            if next_purchase_prediction[0] == 1:\n",
    "                st.write(\"Prediction: The customer is likely to make a next purchase (based on model prediction).\")\n",
    "            else:\n",
    "                st.write(\"Prediction: The customer is unlikely to make a next purchase.\")\n",
    "    else:\n",
    "        st.error(\"Purchase model is not loaded, unable to make predictions.\")\n",
    "\n",
    "# Button to predict next product\n",
    "if st.sidebar.button(\"Predict Next Product\"):\n",
    "    if product_model is not None:\n",
    "        # Predict the next product using the pre-trained product model\n",
    "        next_product_prediction = product_model.predict(X_input)\n",
    "\n",
    "        # Display the prediction\n",
    "        st.write(f\"Prediction: The customer is likely to buy {next_product_prediction[0]}.\")\n",
    "    else:\n",
    "        st.error(\"Product model is not loaded, unable to make predictions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "mZt1GmGRESKA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M5uWIc5ki6Xq",
    "outputId": "a24825fb-fd96-4572-b0a4-d3d81c2e9639"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
      " * ngrok tunnel \"NgrokTunnel: \"https://e534-34-48-129-129.ngrok-free.app\" -> \"http://localhost:8501\"\" -> \"http://127.0.0.1:8501\"\n",
      "\n",
      "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
      "\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
      "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.48.129.129:8501\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Stopping...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pyngrok import ngrok\n",
    "\n",
    "# Set up ngrok authentication (replace with your actual token)\n",
    "!ngrok authtoken \"2sdUCVAqBtQ9Q3z4nzibCdbMqDi_3zFPL2qMszQHDrsoQhnFe\"  # Replace with your actual token\n",
    "\n",
    "# Set up a tunnel to the streamlit app\n",
    "public_url = ngrok.connect(\"http://localhost:8501\")\n",
    "print(f\" * ngrok tunnel \\\"{public_url}\\\" -> \\\"http://127.0.0.1:8501\\\"\")\n",
    "\n",
    "# Run the Streamlit app\n",
    "!streamlit run app.py &\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "o-DSUVJIpJ-H"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
